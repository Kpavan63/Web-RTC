<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Advanced Object Detection Assistant</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            background-color: #f0f4f8;
            display: flex;
            flex-direction: column;
            align-items: center;
            padding: 0;
            margin: 0;
        }
        header {
            width: 100%;
            padding: 15px;
            background-color: #4caf50;
            color: white;
            text-align: center;
            font-size: 24px;
        }
        .container {
            max-width: 800px;
            width: 100%;
            padding: 20px;
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 20px;
        }
        video, canvas {
            width: 100%;
            border-radius: 12px;
            border: 3px solid #4caf50;
        }
        .btn {
            padding: 10px 20px;
            background-color: #4caf50;
            color: white;
            border: none;
            border-radius: 8px;
            cursor: pointer;
            font-size: 16px;
            margin: 5px;
        }
        .btn:hover {
            background-color: #66bb6a;
        }
        #loading {
            display: none;
            color: #4caf50;
        }
        #objectInfo {
            margin-top: 10px;
            color: #333;
        }
    </style>
</head>
<body>

<header>Advanced Object Detection Assistant</header>

<div class="container">
    <select id="languageSelect" class="btn">
        <option value="en">English</option>
        <option value="es">Spanish</option>
        <option value="fr">French</option>
        <option value="te">Telugu</option>
    </select>
    <button class="btn" id="takePhotoButton">Take Photo</button>
    <p id="loading">Detecting objects, please wait...</p>
    <video id="videoInput" autoplay playsinline></video>
    <canvas id="canvasOutput"></canvas>
    <p id="objectInfo"></p>
</div>

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>

<script>
    const video = document.getElementById('videoInput');
    const canvas = document.getElementById('canvasOutput');
    const ctx = canvas.getContext('2d');
    const loadingText = document.getElementById('loading');
    const objectInfo = document.getElementById('objectInfo');
    let model;

    async function startCamera() {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'environment' } });
            video.srcObject = stream;
        } catch (error) {
            console.error('Error accessing the camera:', error);
            alert('Please enable camera permissions.');
        }
    }

    async function loadModel() {
        model = await cocoSsd.load();
        console.log('Model Loaded!');
    }

    async function takePhoto() {
        loadingText.style.display = 'block';
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

        const predictions = await model.detect(canvas);
        displayDetectedObjects(predictions);
        speakDetectedItems(predictions);

        loadingText.style.display = 'none';
    }

    function displayDetectedObjects(predictions) {
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

        predictions.forEach(prediction => {
            ctx.beginPath();
            ctx.rect(...prediction.bbox);
            ctx.lineWidth = 2;
            ctx.strokeStyle = 'red';
            ctx.fillStyle = 'red';
            ctx.stroke();
            ctx.fillText(prediction.class, prediction.bbox[0], prediction.bbox[1] > 10 ? prediction.bbox[1] - 5 : 10);
        });

        // Add clickable event for each detected object
        canvas.onclick = (event) => {
            const x = event.offsetX, y = event.offsetY;
            const clickedObject = predictions.find(prediction => 
                x >= prediction.bbox[0] &&
                x <= prediction.bbox[0] + prediction.bbox[2] &&
                y >= prediction.bbox[1] &&
                y <= prediction.bbox[1] + prediction.bbox[3]
            );
            if (clickedObject) {
                objectInfo.textContent = `Clicked on: ${clickedObject.class}`;
            }
        };
    }

    function speakDetectedItems(predictions) {
        const utterance = new SpeechSynthesisUtterance();
        utterance.lang = document.getElementById('languageSelect').value;
        utterance.text = "Detected items: " + predictions.map(pred => pred.class).join(", ");
        speechSynthesis.speak(utterance);
    }

    document.getElementById('takePhotoButton').addEventListener('click', takePhoto);
    startCamera();
    loadModel();
</script>

</body>
</html>
