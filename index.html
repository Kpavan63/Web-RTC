<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Interactive Object Detection Assistant</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            background-color: #f0f4f8;
            display: flex;
            flex-direction: column;
            align-items: center;
            padding: 0;
            margin: 0;
        }
        header {
            width: 100%;
            padding: 15px;
            background-color: #4caf50;
            color: white;
            text-align: center;
            font-size: 24px;
        }
        .container {
            max-width: 800px;
            width: 100%;
            position: relative;
        }
        video, canvas {
            width: 100%;
            border-radius: 12px;
            border: 3px solid #4caf50;
        }
        .btn {
            position: absolute;
            bottom: 20px;
            left: 50%;
            transform: translateX(-50%);
            background-color: #4caf50;
            border: none;
            border-radius: 50%;
            width: 60px;
            height: 60px;
            display: flex;
            align-items: center;
            justify-content: center;
            cursor: pointer;
            font-size: 24px;
            color: white;
        }
        .btn:hover {
            background-color: #66bb6a;
        }
        #loading {
            display: none;
            color: #4caf50;
            text-align: center;
            margin-top: 10px;
        }
        #objectInfo {
            margin-top: 10px;
            color: #333;
            text-align: center;
        }
        .detected {
            position: absolute;
            border: 2px solid yellow;
            border-radius: 8px;
        }
    </style>
</head>
<body>

<header>Interactive Object Detection Assistant</header>

<div class="container">
    <video id="videoInput" autoplay playsinline></video>
    <canvas id="canvasOutput"></canvas>
    <button class="btn" id="takePhotoButton">ðŸ“¸</button>
    <p id="loading">Loading model...</p>
    <p id="objectInfo"></p>
</div>

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>

<script>
    const video = document.getElementById('videoInput');
    const canvas = document.getElementById('canvasOutput');
    const ctx = canvas.getContext('2d');
    const loadingText = document.getElementById('loading');
    const objectInfo = document.getElementById('objectInfo');
    let model;
    let predictions = [];
    let isDetecting = false;

    // Start the camera
    async function startCamera() {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'environment' } });
            video.srcObject = stream;
        } catch (error) {
            console.error('Error accessing the camera:', error);
            alert('Please enable camera permissions.');
        }
    }

    // Load the COCO-SSD model
    async function loadModel() {
        loadingText.style.display = 'block';
        model = await cocoSsd.load();
        loadingText.style.display = 'none';
        console.log('Model Loaded!');
        isDetecting = true;
        detectObjects();
    }

    // Detect objects continuously
    async function detectObjects() {
        while (isDetecting) {
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

            predictions = await model.detect(canvas);
            displayDetectedObjects();
            await new Promise(resolve => setTimeout(resolve, 1000)); // Adjust detection frequency
        }
    }

    // Function to display detected objects
    function displayDetectedObjects() {
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

        // Unique objects already spoken
        const spokenObjects = new Set();

        predictions.forEach(prediction => {
            const [x, y, width, height] = prediction.bbox;

            // Draw bounding box
            ctx.strokeStyle = 'red';
            ctx.lineWidth = 2;
            ctx.strokeRect(x, y, width, height);
            ctx.fillStyle = 'red';
            ctx.font = '16px Arial';
            ctx.fillText(prediction.class, x, y > 10 ? y - 5 : 10); // Label above bounding box

            // Speak the object name only if it hasn't been spoken yet
            if (!spokenObjects.has(prediction.class)) {
                speak(prediction.class);
                spokenObjects.add(prediction.class);
            }
        });

        // Clear predictions after processing
        objectInfo.textContent = predictions.map(p => p.class).join(', ');
    }

    // Function to synthesize speech
    function speak(text) {
        const utterance = new SpeechSynthesisUtterance();
        utterance.lang = 'te-IN'; // Telugu language
        utterance.text = text;
        window.speechSynthesis.speak(utterance);
    }

    // Event listener for taking a photo (optional)
    document.getElementById('takePhotoButton').addEventListener('click', () => {
        isDetecting = !isDetecting; // Toggle detection on button click
        if (isDetecting) {
            detectObjects();
        } else {
            objectInfo.textContent = "Detection paused.";
        }
    });

    startCamera();
    loadModel();
</script>

</body>
</html>
