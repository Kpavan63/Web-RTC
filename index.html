<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Real-Time Object Detection with Bounding Boxes</title>
  <style>
    body {
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      font-family: Arial, sans-serif;
      height: 100vh;
      margin: 0;
    }
    #canvas {
      position: absolute;
      top: 0;
      left: 0;
    }
    #video {
      width: 100%;
      max-width: 600px;
      border: 2px solid #4CAF50;
      border-radius: 8px;
      margin-top: 20px;
    }
    .btn {
      padding: 10px 20px;
      margin-top: 10px;
      background-color: #4CAF50;
      color: white;
      border: none;
      cursor: pointer;
      border-radius: 5px;
    }
  </style>
</head>
<body>

  <h1>Object Detection Camera</h1>
  <button class="btn" onclick="toggleCamera()">Switch Camera</button>
  <video id="video" autoplay playsinline></video>
  <canvas id="canvas"></canvas>

  <!-- TensorFlow.js Library -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <!-- COCO-SSD Model -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>

  <script>
    let video = document.getElementById('video');
    let canvas = document.getElementById('canvas');
    let context = canvas.getContext('2d');
    let model;
    let useFrontCamera = true;
    let videoStream;

    // Load the COCO-SSD model
    async function loadModel() {
      model = await cocoSsd.load();
      console.log("Model Loaded!");
      detectObjects(); // Start detecting objects
    }

    // Toggle between front and back cameras
    function toggleCamera() {
      useFrontCamera = !useFrontCamera;
      startCamera();
    }

    // Start the camera and set up the video stream
    async function startCamera() {
      if (videoStream) {
        videoStream.getTracks().forEach(track => track.stop()); // Stop previous stream
      }
      const constraints = {
        video: {
          facingMode: useFrontCamera ? "user" : "environment"
        }
      };
      try {
        videoStream = await navigator.mediaDevices.getUserMedia(constraints);
        video.srcObject = videoStream;
        video.onloadedmetadata = () => {
          video.play();
          canvas.width = video.videoWidth;
          canvas.height = video.videoHeight;
        };
      } catch (error) {
        console.error("Error accessing camera:", error);
        alert("Unable to access the camera. Please check permissions.");
      }
    }

    // Detect objects in the video feed and draw bounding boxes
    async function detectObjects() {
      if (model && video) {
        const predictions = await model.detect(video);

        // Clear the canvas
        context.clearRect(0, 0, canvas.width, canvas.height);

        // Draw each detected object's bounding box and label
        predictions.forEach(prediction => {
          const [x, y, width, height] = prediction.bbox;
          context.strokeStyle = "#FF0000";
          context.lineWidth = 2;
          context.strokeRect(x, y, width, height);

          context.fillStyle = "#FF0000";
          context.font = "16px Arial";
          context.fillText(`${prediction.class} - ${Math.round(prediction.score * 100)}%`, x, y > 10 ? y - 5 : 10);
        });

        // Run object detection continuously
        requestAnimationFrame(detectObjects);
      }
    }

    // Load the model and start the camera
    loadModel();
    startCamera();
  </script>

</body>
</html>
